{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LangChain Fundamentals & Agent Building\n",
    "## INSTRUCTOR GUIDE\n",
    "\n",
    "**Duration:** 45 minutes\n",
    "\n",
    "**This guide mirrors the student workbook and provides:**\n",
    "- Solutions to all TODO exercises\n",
    "- Common errors and how to fix them\n",
    "- Talking points for each section\n",
    "- Timing guidance\n",
    "\n",
    "---\n",
    "\n",
    "## Workshop Structure\n",
    "\n",
    "| Time | Section | Duration |\n",
    "|------|---------|----------|\n",
    "| 0:00-0:03 | Part 1: What is LangChain? | 3 min |\n",
    "| 0:03-0:08 | Part 2: Setup | 5 min |\n",
    "| 0:08-0:15 | Part 3: First LLM Call + Exercise 1 | 7 min |\n",
    "| 0:15-0:20 | Part 3.5: Output Parsers | 5 min |\n",
    "| 0:20-0:27 | Part 3.6: Chains | 7 min |\n",
    "| 0:27-0:37 | Part 4: Building Your First Agent | 10 min |\n",
    "| 0:37-0:45 | Part 5: Student Exercise | 8 min |\n",
    "\n",
    "---\n",
    "\n",
    "## Pre-Workshop Checklist\n",
    "\n",
    "- [ ] `.env` file created with valid `OPENAI_API_KEY`\n",
    "- [ ] Virtual environment activated with requirements.txt installed\n",
    "- [ ] Tested all code cells yourself\n",
    "- [ ] Internet connection working\n",
    "- [ ] Know the fallback: `gpt-3.5-turbo` if `gpt-4-turbo` unavailable\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: What is LangChain?\n",
    "## Talking Points (3 minutes)\n",
    "\n",
    "### Key Message\n",
    "\"LangChain is a framework that makes building AI applications easy. Without it, you write 200 lines of boilerplate. With it, 5-10 lines.\"\n",
    "\n",
    "### Analogies That Work\n",
    "- \"LangChain is to AI apps what Django is to web apps\"\n",
    "- \"It's like the `requests` library but for LLMs\"\n",
    "\n",
    "### What It Solves\n",
    "- API calls are verbose → Simple interface\n",
    "- Memory management is manual → Built-in memory\n",
    "- Tool integration requires custom code → Tool framework\n",
    "- Result: Clean, maintainable code\n",
    "\n",
    "### Job Market Hook (Motivating!)\n",
    "> \"80% of AI engineering jobs now list LangChain as a requirement. Starting salary: £50-70k. With 2 years experience: £90-130k.\"\n",
    "\n",
    "### Common Questions\n",
    "\n",
    "**Q: \"Is LangChain the same as ChatGPT?\"**\n",
    "> A: No. ChatGPT is a product you use. LangChain is a framework for developers building AI systems.\n",
    "\n",
    "**Q: \"Do I need to know this?\"**\n",
    "> A: Increasingly yes. It's becoming the industry standard.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Setup\n",
    "## Talking Points (5 minutes)\n",
    "\n",
    "### Walk Through These Steps With Students\n",
    "\n",
    "**Step 1: Virtual Environment** (they should have done this before)\n",
    "```bash\n",
    "python -m venv venv\n",
    ".\\venv\\Scripts\\Activate   # Windows\n",
    "source venv/bin/activate  # Mac/Linux\n",
    "```\n",
    "\n",
    "**Step 2: Install Dependencies**\n",
    "```bash\n",
    "pip install -r requirements.txt\n",
    "```\n",
    "\n",
    "**Step 3: Create .env File**\n",
    "Students create a `.env` file in the project folder with:\n",
    "```\n",
    "OPENAI_API_KEY=sk-your-key-here\n",
    "```\n",
    "\n",
    "**Step 4: Select Kernel**\n",
    "Top-right in VS Code → Select the venv as Jupyter kernel\n",
    "\n",
    "### What Students Should See\n",
    "When they run the setup cell, they should see:\n",
    "```\n",
    "✓ If you've completed the setup steps above, you're ready to go!\n",
    "```\n",
    "\n",
    "When they run the API key cell, they should see:\n",
    "```\n",
    "✓ API key loaded successfully\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## Common Setup Errors\n",
    "\n",
    "### Error: `ModuleNotFoundError: No module named 'dotenv'`\n",
    "**Cause:** Virtual environment not activated or packages not installed\n",
    "\n",
    "**Solution:**\n",
    "1. Check terminal shows `(venv)` prefix\n",
    "2. Run: `pip install -r requirements.txt`\n",
    "3. Restart the Jupyter kernel\n",
    "\n",
    "---\n",
    "\n",
    "### Error: \"API key not found\"\n",
    "**Cause:** .env file missing or in wrong location\n",
    "\n",
    "**Solution:**\n",
    "1. Ensure `.env` file is in the project root (same folder as notebook)\n",
    "2. Check the file contains `OPENAI_API_KEY=sk-...` (no quotes needed)\n",
    "3. Restart kernel after creating .env\n",
    "\n",
    "---\n",
    "\n",
    "### Error: \"Invalid API key\"\n",
    "**Cause:** Key is wrong or expired\n",
    "\n",
    "**Solution:**\n",
    "1. Go to https://platform.openai.com/api-keys\n",
    "2. Create a new key\n",
    "3. Copy entire key including `sk-` prefix\n",
    "4. Update .env file\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3: Your First LLM Call\n",
    "## Talking Points (7 minutes)\n",
    "\n",
    "### Teaching Script\n",
    "> \"Alright, let's build your first LLM app. This is 5 lines of code.\"\n",
    "\n",
    "### What to Emphasise As You Type\n",
    "- **Line 1:** `from langchain_openai import ChatOpenAI` — \"Import the LLM class\"\n",
    "- **Line 2:** `llm = ChatOpenAI(...)` — \"Create an instance, connect to OpenAI\"\n",
    "- **Line 3:** `prompt = \"...\"` — \"This is what we ask\"\n",
    "- **Line 4:** `response = llm.invoke(prompt)` — \"Send it, get response\"\n",
    "- **Line 5:** `print(response.content)` — \"Get the text (not the whole object)\"\n",
    "\n",
    "### Key Concepts Table\n",
    "| Concept | Meaning |\n",
    "|---------|---------|\n",
    "| **Model** | Which LLM (gpt-4-turbo, gpt-3.5-turbo) |\n",
    "| **Temperature** | Creativity: 0=precise, 1=random |\n",
    "| **Prompt** | What you ask |\n",
    "| **response.content** | The actual text (response has metadata too) |\n",
    "\n",
    "### Common Questions\n",
    "\n",
    "**Q: \"Why temperature 0.7?\"**\n",
    "> A: Middle ground. 0 is precise (good for agents), 0.7+ is creative.\n",
    "\n",
    "**Q: \"What's response.content?\"**\n",
    "> A: The response is an object with metadata. We just want the text, so `.content`.\n",
    "\n",
    "**Q: \"How much does this cost?\"**\n",
    "> A: About £0.001 per call. You get £5 free credits from OpenAI.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SETUP: Load API key (same as student notebook)\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "if os.environ.get(\"OPENAI_API_KEY\"):\n",
    "    print(\"✓ API key loaded successfully\")\n",
    "else:\n",
    "    print(\"✗ API key not found - check .env file\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demo: First LLM Call\n",
    "\n",
    "### Run this cell while explaining each line\n",
    "Type slowly! Don't copy-paste during demo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEMO: Simple LLM Call (same as student notebook)\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-4-turbo\",\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "prompt = \"What is the best colour and why?\"\n",
    "response = llm.invoke(prompt)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"LLM RESPONSE:\")\n",
    "print(\"=\"*60)\n",
    "print(response.content)\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1: Student TODO - Write Your Own Prompt\n",
    "\n",
    "### What Students See\n",
    "```python\n",
    "# TODO: Write your own prompt and get a response!\n",
    "```\n",
    "\n",
    "### Example Solutions\n",
    "\n",
    "**Solution 1:**\n",
    "```python\n",
    "my_prompt = \"Why is Python better than JavaScript?\"\n",
    "response = llm.invoke(my_prompt)\n",
    "print(response.content)\n",
    "```\n",
    "\n",
    "**Solution 2:**\n",
    "```python\n",
    "my_prompt = \"What's a cool fact about AI?\"\n",
    "response = llm.invoke(my_prompt)\n",
    "print(response.content)\n",
    "```\n",
    "\n",
    "**Solution 3:**\n",
    "```python\n",
    "my_prompt = \"Tell me a funny joke about programming\"\n",
    "response = llm.invoke(my_prompt)\n",
    "print(response.content)\n",
    "```\n",
    "\n",
    "### Common Errors\n",
    "\n",
    "**Error: `NameError: name 'llm' is not defined`**\n",
    "> Student skipped the demo cell. Have them run it first.\n",
    "\n",
    "**Error: Connection timeout**\n",
    "> Internet issue or OpenAI down. Wait 30 seconds, try again.\n",
    "\n",
    "**Error: Rate limit exceeded**\n",
    "> Too many calls. Wait 1 minute.\n",
    "\n",
    "### Acceptance Criteria\n",
    "- Cell runs without error\n",
    "- LLM returns a response related to the prompt\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3.5: Output Parsers\n",
    "## Talking Points (5 minutes)\n",
    "\n",
    "### Key Message\n",
    "> \"When you call an LLM, you get an AIMessage object. Output parsers extract and structure the response.\"\n",
    "\n",
    "### Two Main Parsers\n",
    "\n",
    "| Parser | Use Case | Output |\n",
    "|--------|----------|--------|\n",
    "| `StrOutputParser` | Get plain text | `str` |\n",
    "| `JsonOutputParser` | Get structured data | `dict` |\n",
    "\n",
    "### Teaching Script\n",
    "> \"Watch the types. Before parsing: AIMessage object. After StrOutputParser: plain string. After JsonOutputParser: Python dictionary.\"\n",
    "\n",
    "### Why This Matters\n",
    "- Clean text for display\n",
    "- Structured data for further processing\n",
    "- Foundation for chains (parsers go at the end)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEMO: Output Parsers (same as student notebook)\n",
    "from langchain_core.output_parsers import StrOutputParser, JsonOutputParser\n",
    "\n",
    "# StrOutputParser - extracts plain text\n",
    "str_parser = StrOutputParser()\n",
    "\n",
    "response = llm.invoke(\"What is the capital of France? Reply in one word.\")\n",
    "text_only = str_parser.invoke(response)\n",
    "\n",
    "print(\"=\" * 50)\n",
    "print(\"StrOutputParser Demo\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Raw response type: {type(response)}\")\n",
    "print(f\"Parsed text type:  {type(text_only)}\")\n",
    "print(f\"Parsed value: {text_only}\")\n",
    "\n",
    "# JsonOutputParser - for structured data\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"JsonOutputParser Demo\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "json_parser = JsonOutputParser()\n",
    "response2 = llm.invoke(\"Return a JSON object with keys 'capital' and 'country' for France. Only return the JSON.\")\n",
    "parsed_json = json_parser.invoke(response2)\n",
    "\n",
    "print(f\"Parsed type: {type(parsed_json)}\")\n",
    "print(f\"Parsed value: {parsed_json}\")\n",
    "print(f\"Access 'capital': {parsed_json.get('capital', 'N/A')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3.6: Chains - The Heart of LangChain\n",
    "## Talking Points (7 minutes)\n",
    "\n",
    "### Key Message\n",
    "> \"The name says it all: **Lang**uage model **Chain**ing. Connect components with the pipe operator `|`\"\n",
    "\n",
    "### Before vs After\n",
    "**Without chains:**\n",
    "```python\n",
    "prompt = template.format(topic=\"AI\")\n",
    "response = llm.invoke(prompt)\n",
    "text = parser.invoke(response)\n",
    "```\n",
    "\n",
    "**With chains:**\n",
    "```python\n",
    "chain = template | llm | parser\n",
    "text = chain.invoke({\"topic\": \"AI\"})\n",
    "```\n",
    "\n",
    "### Why This Matters\n",
    "- Same result, cleaner code\n",
    "- Swap any component without rewriting\n",
    "- Foundation for agents\n",
    "\n",
    "### Visual\n",
    "```\n",
    "Prompt  →  LLM  →  Parser  →  Output\n",
    "   |         |        |\n",
    "   └─────────┴────────┘\n",
    "         CHAIN\n",
    "```\n",
    "\n",
    "### Bridging to Agents\n",
    "> \"Chains flow one direction. Agents can loop and make decisions. Agents are just chains that decide their own steps!\"\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DEMO: Chains with Pipe Operator (same as student notebook)\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# Step 1: Create a prompt template\n",
    "prompt_template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a helpful assistant that explains topics simply.\"),\n",
    "    (\"user\", \"Explain {topic} in one sentence for a beginner.\")\n",
    "])\n",
    "\n",
    "# Step 2: Create the chain using | (pipe operator)\n",
    "chain = prompt_template | llm | StrOutputParser()\n",
    "\n",
    "# Step 3: Run the chain\n",
    "print(\"=\" * 60)\n",
    "print(\"CHAIN DEMO: Prompt → LLM → Parser\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "result = chain.invoke({\"topic\": \"machine learning\"})\n",
    "print(f\"Topic: machine learning\")\n",
    "print(f\"Output: {result}\")\n",
    "\n",
    "result2 = chain.invoke({\"topic\": \"neural networks\"})\n",
    "print(f\"\\nTopic: neural networks\")\n",
    "print(f\"Output: {result2}\")\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"Notice: One chain, multiple uses. This is the power of LangChain!\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 4: Building Your First Agent\n",
    "## Talking Points (10 minutes)\n",
    "\n",
    "### Key Message\n",
    "> \"An agent is a chain that can make decisions and use tools.\"\n",
    "\n",
    "### Visual Comparison\n",
    "```\n",
    "CHAIN:    prompt → llm → parser → done\n",
    "\n",
    "AGENT:    prompt → llm → tool? → observation → llm → tool? → ... → done\n",
    "                    ↑__________________________|\n",
    "                         (loops until solved)\n",
    "```\n",
    "\n",
    "### What Makes Agents Special\n",
    "- **Decides** which tool to use based on the question\n",
    "- **Reads** the tool result\n",
    "- **Loops** until the task is complete\n",
    "\n",
    "### Key Difference\n",
    "- Without tools: LLM only knows training data\n",
    "- With tools: LLM can access real-time data, compute, anything\n",
    "\n",
    "---\n",
    "\n",
    "## Step 1: Define Tools\n",
    "\n",
    "### Teaching Script\n",
    "> \"A tool is a Python function with the @tool decorator. The docstring is crucial - the agent reads it to decide when to use the tool.\"\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEMO: Define Tools (same as student notebook)\n",
    "from langchain.tools import tool\n",
    "\n",
    "@tool\n",
    "def search_wikipedia(query: str) -> str:\n",
    "    \"\"\"\n",
    "    Search Wikipedia for information about a topic.\n",
    "    Use this to find facts and background information.\n",
    "    \"\"\"\n",
    "    # Simulated response for demo purposes\n",
    "    return f\"Wikipedia results for '{query}': [Found detailed information about {query}]\"\n",
    "\n",
    "# NOTE: Student notebook has a TODO for a calculator tool\n",
    "# Here's the solution if students ask:\n",
    "\n",
    "@tool\n",
    "def calculate(expression: str) -> str:\n",
    "    \"\"\"\n",
    "    Calculate a mathematical expression.\n",
    "    Use this for maths problems like '2 + 2' or '15 * 12'.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        result = eval(expression)\n",
    "        return f\"Result: {expression} = {result}\"\n",
    "    except:\n",
    "        return f\"Error: Could not calculate {expression}\"\n",
    "\n",
    "print(\"✓ Tools defined:\")\n",
    "print(\"  - search_wikipedia\")\n",
    "print(\"  - calculate\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Create the Agent\n",
    "\n",
    "### Teaching Script\n",
    "> \"We use LangGraph's `create_react_agent` to create the agent. It's the modern way to build agents in LangChain.\"\n",
    "\n",
    "### Important Notes\n",
    "- We use `langgraph.prebuilt` not the old `langchain.agents`\n",
    "- `create_react_agent` handles all the complexity for us\n",
    "- Temperature=0 for agents (deterministic decisions)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEMO: Create Agent using LangGraph (same as student notebook)\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "\n",
    "# Create the LLM (temperature=0 for deterministic agent decisions)\n",
    "llm = ChatOpenAI(model=\"gpt-4-turbo\", temperature=0)\n",
    "\n",
    "# Define which tools the agent can use\n",
    "tools = [search_wikipedia]  # Student notebook only has search_wikipedia by default\n",
    "\n",
    "# Create the agent using LangGraph\n",
    "agent = create_react_agent(llm, tools)\n",
    "\n",
    "print(\"✓ Agent created and ready to use\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Run the Agent\n",
    "\n",
    "### Teaching Script\n",
    "> \"Watch what happens. The agent sees the question, decides which tool to use, and gives you an answer.\"\n",
    "\n",
    "### Important Syntax Note\n",
    "With LangGraph, we use:\n",
    "```python\n",
    "agent.invoke({\"messages\": [(\"user\", \"Your question\")]})\n",
    "```\n",
    "\n",
    "Not the old `{\"input\": \"...\"}` syntax.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEMO: Run the Agent (same as student notebook)\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"AGENT DEMO\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "result = agent.invoke({\n",
    "    \"messages\": [(\"user\", \"What is 15 * 12? Then search for what that number means.\")]\n",
    "})\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"FINAL ANSWER:\")\n",
    "print(\"=\"*70)\n",
    "print(result[\"messages\"][-1].content)\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What Just Happened?\n",
    "\n",
    "### Agent's Thought Process\n",
    "1. Received question about calculation and search\n",
    "2. Computed 15 * 12 = 180 (even without calculator tool, LLM can do basic math)\n",
    "3. Used search_wikipedia tool to find info about 180\n",
    "4. Synthesised final answer\n",
    "\n",
    "### Key Insight\n",
    "> \"The agent DECIDED what to do. It wasn't programmed to search - it chose to!\"\n",
    "\n",
    "### Common Questions\n",
    "\n",
    "**Q: \"How does the agent know which tool to use?\"**\n",
    "> A: It reads the tool descriptions (docstrings) and decides based on context.\n",
    "\n",
    "**Q: \"Can the agent use multiple tools?\"**\n",
    "> A: Yes! It can chain tools together automatically.\n",
    "\n",
    "**Q: \"What if the agent picks the wrong tool?\"**\n",
    "> A: It sees the result and can adjust. It might try a different tool.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 5: Build Your Own Agent - Student Exercise\n",
    "## Duration: 8 minutes\n",
    "\n",
    "### What Students See\n",
    "\n",
    "The student notebook has:\n",
    "1. A markdown cell with tool ideas table\n",
    "2. A code cell with template tools and TODO comments\n",
    "\n",
    "### Tool Ideas Table (in student notebook)\n",
    "| Tool Idea | What it does |\n",
    "|-----------|-------------|\n",
    "| `get_weather` | Returns weather for a city (simulated) |\n",
    "| `translate_text` | Translates text to another language |\n",
    "| `summarise_text` | Condenses long text into bullet points |\n",
    "| `get_stock_price` | Returns a stock price (simulated) |\n",
    "| `generate_password` | Creates a secure random password |\n",
    "| `convert_units` | Converts between units (km to miles, etc.) |\n",
    "\n",
    "### Encourage Creativity\n",
    "> \"Don't just change the prompt - build something that solves a problem YOU care about!\"\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example Solutions for Student Exercise\n",
    "\n",
    "### Solution 1: Weather Tool (Simple)\n",
    "```python\n",
    "@tool\n",
    "def get_weather(city: str) -> str:\n",
    "    \"\"\"Get the current weather for a city.\"\"\"\n",
    "    # Simulated - in real life would call weather API\n",
    "    return f\"Weather in {city}: Sunny, 22°C\"\n",
    "\n",
    "my_tools = [get_weather]\n",
    "my_agent = create_react_agent(llm, my_tools)\n",
    "\n",
    "result = my_agent.invoke({\n",
    "    \"messages\": [(\"user\", \"What's the weather in London?\")]\n",
    "})\n",
    "print(result[\"messages\"][-1].content)\n",
    "```\n",
    "\n",
    "### Solution 2: Unit Converter (Medium)\n",
    "```python\n",
    "@tool\n",
    "def convert_units(conversion: str) -> str:\n",
    "    \"\"\"Convert between units. Format: '10 km to miles' or '100 fahrenheit to celsius'\"\"\"\n",
    "    if \"km to miles\" in conversion.lower():\n",
    "        km = float(conversion.split()[0])\n",
    "        return f\"{km} km = {km * 0.621371:.2f} miles\"\n",
    "    elif \"fahrenheit to celsius\" in conversion.lower():\n",
    "        f = float(conversion.split()[0])\n",
    "        return f\"{f}°F = {(f - 32) * 5/9:.1f}°C\"\n",
    "    return \"Conversion not supported\"\n",
    "```\n",
    "\n",
    "### Solution 3: Multiple Tools (Advanced)\n",
    "```python\n",
    "@tool\n",
    "def get_stock_price(symbol: str) -> str:\n",
    "    \"\"\"Get the current stock price for a ticker symbol.\"\"\"\n",
    "    # Simulated prices\n",
    "    prices = {\"AAPL\": 175.50, \"GOOGL\": 140.25, \"MSFT\": 380.00}\n",
    "    return f\"{symbol}: ${prices.get(symbol.upper(), 'Unknown')}\"\n",
    "\n",
    "@tool\n",
    "def calculate_profit(expression: str) -> str:\n",
    "    \"\"\"Calculate profit. Format: 'bought at 100, now 150'\"\"\"\n",
    "    # Simple profit calculation\n",
    "    return f\"Profit calculation for: {expression}\"\n",
    "\n",
    "my_tools = [get_stock_price, calculate_profit]\n",
    "```\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WORKING EXAMPLE: Build Your Own Agent (Teacher's Version)\n",
    "# This shows a complete working solution\n",
    "\n",
    "@tool\n",
    "def get_weather(city: str) -> str:\n",
    "    \"\"\"Get the current weather for a city.\"\"\"\n",
    "    weather_data = {\n",
    "        \"london\": \"Cloudy, 15°C, 60% humidity\",\n",
    "        \"paris\": \"Sunny, 22°C, 40% humidity\",\n",
    "        \"new york\": \"Rainy, 18°C, 80% humidity\",\n",
    "    }\n",
    "    return weather_data.get(city.lower(), f\"Weather data not available for {city}\")\n",
    "\n",
    "@tool\n",
    "def get_greeting(name: str) -> str:\n",
    "    \"\"\"Generate a personalised greeting for someone.\"\"\"\n",
    "    return f\"Hello {name}! Welcome to the AI workshop. Hope you're having fun!\"\n",
    "\n",
    "# Create agent with custom tools\n",
    "my_tools = [get_weather, get_greeting]\n",
    "my_agent = create_react_agent(llm, my_tools)\n",
    "\n",
    "# Test it\n",
    "result = my_agent.invoke({\n",
    "    \"messages\": [(\"user\", \"Greet Alex, then tell me the weather in London\")]\n",
    "})\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"CUSTOM AGENT RESPONSE:\")\n",
    "print(\"=\"*70)\n",
    "print(result[\"messages\"][-1].content)\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## CELL 2: Create the Agent\n",
    "\n",
    "### What Student Sees\n",
    "\n",
    "```python\n",
    "# TODO: Create LLM\n",
    "llm = ChatOpenAI(model=\"gpt-4-turbo\", temperature=0.7)\n",
    "\n",
    "# TODO: Get the agent prompt\n",
    "prompt = hub.pull(\"hwchase17/openai-tools-agent\")\n",
    "\n",
    "# TODO: List your tools\n",
    "tools = [search_colour_facts, search_colour_usage]\n",
    "\n",
    "# TODO: Create the agent\n",
    "agent = create_tool_calling_agent(llm, tools, prompt)\n",
    "\n",
    "# TODO: Create executor\n",
    "executor = AgentExecutor(\n",
    "    agent=agent,\n",
    "    tools=tools,\n",
    "    verbose=True\n",
    ")\n",
    "```\n",
    "\n",
    "### Expected Student Solution\n",
    "\n",
    "**Most students will not change anything here.** The code is already provided.\n",
    "\n",
    "**Some might:**\n",
    "- Change temperature to 0.8 or 0.9 (for more creativity)\n",
    "- Add a 3rd tool to the tools list: `tools = [search_colour_facts, search_colour_usage, search_psychology]`\n",
    "\n",
    "### What You Should See\n",
    "When you run this cell:\n",
    "- Wait 3-5 seconds for hub.pull()\n",
    "- No errors\n",
    "- Output: \"✓ Agent ready\"\n",
    "\n",
    "### Acceptance Criteria\n",
    "- Cell runs without errors\n",
    "- Agent is created successfully\n",
    "- No NameError (they defined tools in cell 1)\n",
    "\n",
    "### Common Issues\n",
    "\n",
    "**Issue: \"hub.pull() connection error\"**\n",
    "- Solution: Internet connectivity issue. Try again or use a different prompt template.\n",
    "- Fallback: Use a manual prompt string instead of hub.pull()\n",
    "\n",
    "**Issue: NameError \"search_colour_facts is not defined\"**\n",
    "- Solution: Student did not run cell 1 first. Have them run it.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# STEP 2: Create the Agent\n",
    "# ============================================\n",
    "\n",
    "# TODO: Create LLM (temperature=0.7 for creativity)\n",
    "llm = ChatOpenAI(model=\"gpt-4-turbo\", temperature=0.7)\n",
    "\n",
    "# TODO: Get the agent prompt template\n",
    "prompt = hub.pull(\"hwchase17/openai-tools-agent\")\n",
    "\n",
    "# TODO: List your tools\n",
    "tools = [search_colour_facts, search_colour_usage]\n",
    "\n",
    "# TODO: Create the agent\n",
    "agent = create_tool_calling_agent(llm, tools, prompt)\n",
    "\n",
    "# TODO: Create executor\n",
    "executor = AgentExecutor(\n",
    "    agent=agent,\n",
    "    tools=tools,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "print(f\"✓ Agent ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## CELL 3: Create Your Prompt\n",
    "\n",
    "### What Student Sees\n",
    "\n",
    "```python\n",
    "# TODO: Write a prompt that makes the agent argue for your colour\n",
    "# The more specific, the better the arguments!\n",
    "# Examples:\n",
    "# - \"You are a passionate RED enthusiast. Argue why RED is the best color!\"\n",
    "# - \"You love GREEN. Why is GREEN superior to all other colors? Use facts!\"\n",
    "# - \"BLUE is clearly the best color. Prove it using your tools.\"\n",
    "\n",
    "my_prompt = f\"\"\"\n",
    "You are a passionate advocate for {MY_COLOUR}.\n",
    "Your job is to argue convincingly why {MY_COLOUR} is the BEST colour.\n",
    "Use your tools to find facts and evidence.\n",
    "Be creative, persuasive, and fun!\n",
    "Give 3-4 strong reasons why {MY_COLOUR} is superior.\n",
    "\"\"\"\n",
    "```\n",
    "\n",
    "### Expected Student Solutions\n",
    "\n",
    "**Solution 1 (Minimal):**\n",
    "```python\n",
    "# They just use the provided prompt template as-is\n",
    "# This is fine! It is a good prompt.\n",
    "```\n",
    "\n",
    "**Solution 2 (Slightly modified):**\n",
    "```python\n",
    "my_prompt = f\"\"\"\n",
    "Pretend you are a passionate {MY_COLOUR} enthusiast.\n",
    "Convince me that {MY_COLOUR} is the best colour in the world.\n",
    "Use your tools to support your argument.\n",
    "Be funny and persuasive.\n",
    "\"\"\"\n",
    "```\n",
    "\n",
    "**Solution 3 (More creative):**\n",
    "```python\n",
    "my_prompt = f\"\"\"\n",
    "You are a marketing executive hired by a {MY_COLOUR} paint company.\n",
    "Write a campaign explaining why {MY_COLOUR} is superior.\n",
    "Use facts and be persuasive.\n",
    "Make it 4-5 sentences.\n",
    "\"\"\"\n",
    "```\n",
    "\n",
    "### What You Should See\n",
    "When you run this cell:\n",
    "- No errors\n",
    "- Output showing \"✓ Prompt created\" and the prompt preview\n",
    "\n",
    "### Acceptance Criteria\n",
    "- my_prompt is not empty\n",
    "- It includes the colour name (via f-string)\n",
    "- It asks the agent to argue or persuade\n",
    "- It mentions using tools (optional but good)\n",
    "\n",
    "### Instructor Tips\n",
    "- Better prompts lead to better agent responses\n",
    "- Prompts that mention \"use your tools\" get agents to use tools more often\n",
    "- Longer prompts with more detail usually get better results\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# STEP 3: Create Your Prompt\n",
    "# ============================================\n",
    "\n",
    "# TODO: Write a prompt that makes the agent argue for your colour\n",
    "# The more specific, the better the arguments!\n",
    "\n",
    "my_prompt = f\"\"\"\n",
    "You are a passionate advocate for {MY_COLOUR}.\n",
    "Your job is to argue convincingly why {MY_COLOUR} is the BEST colour.\n",
    "Use your tools to find facts and evidence.\n",
    "Be creative, persuasive, and fun!\n",
    "Give 3-4 strong reasons why {MY_COLOUR} is superior.\n",
    "\"\"\"\n",
    "\n",
    "print(f\"✓ Prompt created\")\n",
    "print(f\"\\nPrompt preview:\\n{my_prompt}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## CELL 4: Run Your Agent!\n",
    "\n",
    "### What Student Sees\n",
    "\n",
    "```python\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(f\"{MY_COLOUR.upper()} AGENT - MAKING ARGUMENTS\")\n",
    "print(\"=\"*70 + \"\\n\")\n",
    "\n",
    "result = executor.invoke({\"input\": my_prompt})\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"FINAL ARGUMENT:\")\n",
    "print(\"=\"*70)\n",
    "print(result[\"output\"])\n",
    "print(\"=\"*70)\n",
    "```\n",
    "\n",
    "### What You Should See\n",
    "\n",
    "**Verbose output showing:**\n",
    "1. Agent thinking about what to do\n",
    "2. Agent choosing a tool\n",
    "3. Tool result\n",
    "4. More thinking\n",
    "5. Possibly another tool use\n",
    "6. Final answer (3-5 sentences arguing for the colour)\n",
    "\n",
    "**Example output:**\n",
    "```\n",
    "> Entering new AgentExecutor chain...\n",
    "THOUGHT: I need to argue why Blue is the best colour. Let me use my tools to find supporting facts.\n",
    "ACTION: search_colour_facts with topic 'psychology and emotion'\n",
    "OBSERVATION: Found facts: Blue is associated with calmness and trust\n",
    "THOUGHT: Good, now let me search for usage in nature and culture\n",
    "ACTION: search_colour_usage with domain 'nature'\n",
    "OBSERVATION: In nature, Blue is used for water and sky\n",
    "THOUGHT: I have enough facts. Now I can make my argument.\n",
    "\n",
    "FINAL ANSWER:\n",
    "Blue is the best colour for so many reasons. Psychologically, blue promotes calmness, trust, and stability - qualities we all need in life. In nature, blue is everywhere in our skies and oceans, making it the most abundant and essential colour. Blue has been used in art, design, and branding across cultures because it is universally beloved. Finally, blue is the colour of infinite possibilities - the colour of the vast universe and the deepest oceans!\n",
    "```\n",
    "\n",
    "### Acceptance Criteria\n",
    "- No errors\n",
    "- Agent used at least one tool\n",
    "- Agent produced an argument (3-5 sentences)\n",
    "- Argument is related to the colour\n",
    "- Output is printed clearly\n",
    "\n",
    "### Timing\n",
    "- First run: 5-15 seconds depending on API latency\n",
    "- Subsequent runs: 3-10 seconds\n",
    "\n",
    "### Common Issues\n",
    "\n",
    "**Issue: \"Agent didn't use any tools\"**\n",
    "- Problem: The agent decided it didn't need tools\n",
    "- Solution: Reword the prompt to explicitly say \"Use your tools to...\"\n",
    "- Alternative: Make tool names more relevant\n",
    "\n",
    "**Issue: \"Agent is repeating itself or stuck in a loop\"**\n",
    "- Problem: Sometimes happens with certain prompts\n",
    "- Solution: Reduce temperature (0.5 instead of 0.7)\n",
    "- Solution: Reword prompt to be more directive\n",
    "\n",
    "**Issue: \"Agent argument is too short\"**\n",
    "- Problem: Agent gave 1-2 sentences\n",
    "- Solution: Modify prompt to say \"Give a detailed argument with 4-5 sentences\"\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# STEP 4: Run Your Agent!\n",
    "# ============================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(f\"{MY_COLOUR.upper()} AGENT - MAKING ARGUMENTS\")\n",
    "print(\"=\"*70 + \"\\n\")\n",
    "\n",
    "result = executor.invoke({\"input\": my_prompt})\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"FINAL ARGUMENT:\")\n",
    "print(\"=\"*70)\n",
    "print(result[\"output\"])\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Lab Troubleshooting\n",
    "\n",
    "### Issue: \"NameError: name 'executor' is not defined\"\n",
    "- **Cause:** Cell 2 was not run before cell 4\n",
    "- **Solution:** Have student run all cells in order (1, 2, 3, 4)\n",
    "\n",
    "### Issue: \"API Rate Limit\"\n",
    "- **Cause:** Too many API calls from the whole class\n",
    "- **Solution:** Ask class to wait 1 minute before trying again\n",
    "- **Prevention:** Space out when different students run agents\n",
    "\n",
    "### Issue: \"hub.pull() timeout\"\n",
    "- **Cause:** Internet connectivity or hub.langchain.com is down\n",
    "- **Solution:** Provide a fallback prompt template in the cell\n",
    "\n",
    "### Issue: \"Agent response is short/not good\"\n",
    "- **Cause:** Weak prompt or tools not descriptive enough\n",
    "- **Solution:** Guide student to improve the prompt in cell 3\n",
    "- **Tips:**\n",
    "  - Make prompt more specific: \"Use your tools to find at least 3 facts\"\n",
    "  - Give character: \"You are an award-winning colour theorist arguing...\"\n",
    "  - Increase temperature: 0.8 or 0.9 for more creativity\n",
    "\n",
    "### Issue: \"Agent keeps using the same tool over and over\"\n",
    "- **Cause:** Tool names are vague or agent is confused\n",
    "- **Solution:** Reduce temperature to 0.3 to make decisions more deterministic\n",
    "- **Solution:** Rename tools to be more distinct\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extensions for Fast Finishers\n",
    "\n",
    "Have fast students try these:\n",
    "\n",
    "**Extension 1: Add a 3rd Tool**\n",
    "\n",
    "```python\n",
    "@tool\n",
    "def search_psychology(aspect: str) -> str:\n",
    "    \"\"\"Find psychological facts about your colour\"\"\"\n",
    "    return f\"{MY_COLOUR} makes people feel {aspect}\"\n",
    "```\n",
    "\n",
    "Then add it to tools list: `tools = [search_colour_facts, search_colour_usage, search_psychology]`\n",
    "\n",
    "**Extension 2: Make Your Agent Funny**\n",
    "\n",
    "Add to prompt: \"Be sarcastic and funny while arguing\"\n",
    "\n",
    "**Extension 3: Argue Against Another Colour**\n",
    "\n",
    "Add to prompt: \"Also explain why Red is worse than your colour\"\n",
    "\n",
    "**Extension 4: Change the Temperature**\n",
    "\n",
    "```python\n",
    "llm = ChatOpenAI(model=\"gpt-4-turbo\", temperature=0.9)  # More creative\n",
    "```\n",
    "\n",
    "**Extension 5: Add Personality**\n",
    "\n",
    "Change prompt to: \"You are a grumpy 80-year-old art professor arguing why...\" or \"You are a 10-year-old child excitedly explaining why...\"\n",
    "\n",
    "**Extension 6: Create a New Tool Type**\n",
    "\n",
    "```python\n",
    "@tool\n",
    "def count_uses(domain: str) -> str:\n",
    "    \"\"\"Count how many times the colour appears in a domain\"\"\"\n",
    "    return f\"{MY_COLOUR} appears in {domain} more than 100 times!\"\n",
    "```\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART 5: Recap and Handoff\n",
    "## Duration: 10 minutes\n",
    "\n",
    "## What You Learned\n",
    "\n",
    "**LangChain basics:**\n",
    "- What LangChain is and why it matters\n",
    "- How to import and use it\n",
    "\n",
    "**LLMs in Python:**\n",
    "- How to create an LLM instance\n",
    "- How to call it with a prompt\n",
    "- How to get and use the response\n",
    "\n",
    "**Tools:**\n",
    "- What tools are (functions the agent can call)\n",
    "- How to define tools with @tool decorator\n",
    "- How tools give agents real-world capabilities\n",
    "\n",
    "**Agents:**\n",
    "- What agents are (LLMs with decision-making)\n",
    "- How agents decide which tools to use\n",
    "- How to create and run agents\n",
    "- How agents reason and explain their thinking\n",
    "\n",
    "---\n",
    "\n",
    "## Real-World Applications\n",
    "\n",
    "What their code can do:\n",
    "- Chat with documents (agent reads PDFs and answers questions)\n",
    "- Autonomous research (agent finds info from multiple sources)\n",
    "- Code debugging (agent analyses code and suggests fixes)\n",
    "- Data analysis (agent processes data and creates reports)\n",
    "- Customer service (agent handles customer questions with tools)\n",
    "- Task automation (agent decides what actions to take)\n",
    "\n",
    "---\n",
    "\n",
    "## Key Takeaway\n",
    "\n",
    "**You just built what AI engineers do daily.**\n",
    "\n",
    "- Companies like OpenAI, Anthropic, and Google use this exact pattern\n",
    "- This is day 2-3 work at a real AI startup\n",
    "- They have portfolio-ready code\n",
    "- Employers specifically look for this skill\n",
    "\n",
    "---\n",
    "\n",
    "## Common Student Questions After This Lab\n",
    "\n",
    "**Q: Can I make the agent even smarter?**\n",
    "A: Yes! Next, we will learn LangGraph, which lets you chain multiple agents together and add memory.\n",
    "\n",
    "**Q: What if my tool fails?**\n",
    "A: Good question. We need error handling. Wrap your tool in try/except. The agent will see the error and adapt.\n",
    "\n",
    "**Q: Can I deploy this?**\n",
    "A: Absolutely. You can wrap it in a Flask/FastAPI web server and host it on AWS, Heroku, or similar.\n",
    "\n",
    "**Q: Can I use different LLMs?**\n",
    "A: Yes! Replace ChatOpenAI with Claude, Gemini, Llama, etc. The pattern is the same.\n",
    "\n",
    "**Q: How do I make this production-ready?**\n",
    "A: Add: error handling, logging, testing, rate limiting, caching, and monitoring.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary and Next Steps\n",
    "\n",
    "## What's Next?\n",
    "\n",
    "In the next section (LangGraph), students will:\n",
    "\n",
    "- Connect multiple agents working together\n",
    "- Add state management so agents share information\n",
    "- Visualise workflows as diagrams\n",
    "- Build production systems that companies actually deploy\n",
    "\n",
    "**Preview script:** \"What if you had 3 agents: one researches, one analyses, one makes decisions? They would need to pass information between them. That is what we are building next.\"\n",
    "\n",
    "---\n",
    "\n",
    "## Teaching Checklist\n",
    "\n",
    "Before each session:\n",
    "- [ ] Test all code cells yourself\n",
    "- [ ] Check API key is valid\n",
    "- [ ] Verify internet connectivity\n",
    "- [ ] Know how long each cell takes\n",
    "- [ ] Prepare example prompts for demonstrations\n",
    "- [ ] Have fallback solutions ready (e.g., gpt-3.5-turbo if gpt-4-turbo unavailable)\n",
    "\n",
    "During the session:\n",
    "- [ ] Type code slowly (do not copy-paste)\n",
    "- [ ] Explain each line\n",
    "- [ ] Show students the output\n",
    "- [ ] Celebrate when it works\n",
    "- [ ] Encourage students to tinker and experiment\n",
    "- [ ] Walk around checking on student progress\n",
    "- [ ] Help students debug issues\n",
    "\n",
    "After the session:\n",
    "- [ ] Ask for feedback\n",
    "- [ ] Collect student projects for assessment\n",
    "- [ ] Document any issues that came up\n",
    "- [ ] Prepare for next session\n",
    "\n",
    "---\n",
    "\n",
    "## Estimated Costs\n",
    "\n",
    "- Demo 1 (simple LLM call): ~GBP 0.001\n",
    "- Each student Exercise 1: ~GBP 0.001\n",
    "- Agent demo: ~GBP 0.002 (2 tool calls)\n",
    "- Each student lab (4 calls if agent uses 2 tools): ~GBP 0.003\n",
    "- **Total per student: ~GBP 0.01 (1 penny)**\n",
    "- **For 30 students: ~GBP 0.30**\n",
    "\n",
    "Students get GBP 5 free credits. No issue.\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
