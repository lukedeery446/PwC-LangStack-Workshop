{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LangChain Fundamentals & Agent Building\n",
    "## TEACHER'S EDITION - Workshop for University CS Students\n",
    "\n",
    "**Duration:** 45 minutes\n",
    "**Learning Outcomes:**\n",
    "- Understand what LangChain is and why it matters\n",
    "- Build your first LLM-powered agent\n",
    "- Learn core concepts: Prompts, Memory, Tools, Agents\n",
    "- Create portfolio-ready code\n",
    "\n",
    "---\n",
    "\n",
    "## Section Overview\n",
    "\n",
    "| Time | Activity | Duration |\n",
    "|------|----------|----------|\n",
    "| 0:00-0:05 | Conceptual Intro | 5 mins |\n",
    "| 0:05-0:13 | Live Code Demo 1 | 8 mins |\n",
    "| 0:13-0:20 | Building Your First Agent | 7 mins |\n",
    "| 0:20-0:35 | LAB: Colour-Arguing Agent | 15 mins |\n",
    "| 0:35-0:45 | Recap and Handoff | 10 mins |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART 1: What is LangChain? (Conceptual Intro)\n",
    "## Duration: 5 minutes\n",
    "\n",
    "## Teaching Notes\n",
    "\n",
    "### Goal\n",
    "Demystify LangChain and answer \"Why should I care?\"\n",
    "\n",
    "### Key Points to Emphasise\n",
    "1. LangChain solves the \"mess\" of building with LLMs\n",
    "2. It is not magic - just abstractions over API calls\n",
    "3. Every major AI company uses it\n",
    "4. This is day-2 work at OpenAI/Anthropic\n",
    "\n",
    "### Analogies to Use\n",
    "- \"LangChain is like requests library for LLMs\"\n",
    "- \"It is like Django for web dev - LangChain for AI dev\"\n",
    "- \"Without it: 100 lines of boilerplate. With it: 5 lines.\"\n",
    "\n",
    "### Key Concepts to Highlight\n",
    "\n",
    "**The Problem:**\n",
    "- API calls are verbose\n",
    "- Memory management is manual\n",
    "- Error handling everywhere\n",
    "- Tools require custom system\n",
    "- Chains need manual orchestration\n",
    "- Result: 200 lines of boilerplate for simple tasks\n",
    "\n",
    "**The LangChain Solution:**\n",
    "- Simple LLM interface\n",
    "- Built-in memory\n",
    "- Error handling included\n",
    "- Tool framework provided\n",
    "- Agent orchestration built-in\n",
    "- Result: 5-10 lines of clean code\n",
    "\n",
    "### Job Market Context\n",
    "Show students these job postings (optional but motivating):\n",
    "\n",
    "1. **OpenAI - AI Engineer**: \"Experience with LangChain for agent orchestration\" - GBP 120-150k\n",
    "2. **Anthropic - ML Engineer**: \"Build agents using LangChain\" - GBP 130-170k\n",
    "3. **UK FinTech - AI Engineer**: \"Deploy LLM apps with LangChain\" - GBP 90-120k\n",
    "\n",
    "**Stat to mention:** \"80% of AI engineering jobs now require this skill\"\n",
    "\n",
    "### Common Student Questions at This Point\n",
    "\n",
    "**Q: Is LangChain the same as ChatGPT?**\n",
    "A: No. ChatGPT is a product you use. LangChain is a framework for developers. Think of it like: ChatGPT is a car, LangChain is a toolkit for building cars.\n",
    "\n",
    "**Q: Do I need to know LangChain to be an AI engineer?**\n",
    "A: Increasingly yes. It is the industry standard. Most AI jobs now list it as a requirement.\n",
    "\n",
    "**Q: Is this replacing data science?**\n",
    "A: Different skills. Data science focuses on statistics and data. AI engineering (LangChain) focuses on building production systems with LLMs.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART 2: Setup and Hello World\n",
    "\n",
    "## Installation and Setup\n",
    "\n",
    "### Step 1: Install Required Libraries\n",
    "Run this once before the workshop:\n",
    "\n",
    "```bash\n",
    "pip install langchain langchain-openai python-dotenv\n",
    "```\n",
    "\n",
    "### Step 2: Get Your API Key\n",
    "1. Go to https://platform.openai.com/api-keys\n",
    "2. Create new API key\n",
    "3. Copy it (do not share it!)\n",
    "4. Keep it safe\n",
    "\n",
    "### Step 3: Set Environment Variable\n",
    "Create a `.env` file in the project:\n",
    "```\n",
    "OPENAI_API_KEY=sk-your-key-here\n",
    "```\n",
    "\n",
    "### Pre-Workshop Checklist\n",
    "Before teaching, make sure:\n",
    "- [ ] You have a valid OpenAI API key\n",
    "- [ ] You have gpt-4-turbo access (or know a fallback model)\n",
    "- [ ] You tested all cells yourself\n",
    "- [ ] You know how long each cell takes to run\n",
    "- [ ] You have internet connection for hub.pull()\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DEMO 1: Hello World with LangChain\n",
    "## Duration: 8 minutes\n",
    "\n",
    "## Teaching Notes\n",
    "\n",
    "### What to Emphasise\n",
    "- This is as simple as it gets\n",
    "- 5 lines of code equals using a cutting-edge LLM\n",
    "- Show what just happened under the hood\n",
    "- Celebrate when it works\n",
    "\n",
    "### What to Show on Screen\n",
    "- Type EVERY line slowly (do not copy-paste)\n",
    "- Explain each line as you type\n",
    "- Run it\n",
    "- Show the output\n",
    "- Say: \"That is it. That is LangChain.\"\n",
    "\n",
    "### Learning Outcome\n",
    "Students should understand:\n",
    "- How to import LangChain\n",
    "- How to create an LLM instance\n",
    "- How to invoke (call) the LLM\n",
    "- How to get the response\n",
    "\n",
    "### Timing\n",
    "- Setup cell: 1 second\n",
    "- Demo cell: 3-5 seconds (first time)\n",
    "- Explanation: 3-4 minutes\n",
    "- Student attempt: 1-2 minutes\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SETUP: Import libraries\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# For this notebook, you can also set directly (less secure):\n",
    "# os.environ[\"OPENAI_API_KEY\"] = \"sk-your-key-here\"\n",
    "\n",
    "print(\"✓ Setup complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DEMO: Your First LLM Call\n",
    "\n",
    "### Teaching Script\n",
    "\"Alright, let us build your first LLM app. This is 5 lines of code.\"\n",
    "\n",
    "### Type Slowly, Explaining Each Line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEMO 1: Simple LLM Call\n",
    "\n",
    "# Line 1: Import the LLM\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# Line 2: Create an instance (connect to OpenAI)\n",
    "# temperature=0.7 means: how creative (0=factual, 1=creative)\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-4-turbo\",\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "# Line 3: Send a prompt\n",
    "prompt = \"What is the best colour and why?\"\n",
    "\n",
    "# Line 4: Get the response\n",
    "response = llm.invoke(prompt)\n",
    "\n",
    "# Line 5: Print it\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"LLM RESPONSE:\")\n",
    "print(\"=\"*60)\n",
    "print(response.content)\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What Just Happened?\n",
    "\n",
    "### Breaking it Down Line by Line\n",
    "\n",
    "```python\n",
    "from langchain_openai import ChatOpenAI\n",
    "# Import: \"I want to use the ChatOpenAI model from LangChain\"\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4-turbo\", temperature=0.7)\n",
    "# Create: \"Connect to OpenAI's GPT-4, with creativity level 0.7\"\n",
    "# This uses your API key from .env\n",
    "\n",
    "response = llm.invoke(prompt)\n",
    "# Call: \"Send this prompt to the model and get back a response\"\n",
    "# This makes an API call (costs money, but tiny amount)\n",
    "\n",
    "print(response.content)\n",
    "# Display: \"Show me the text that came back\"\n",
    "```\n",
    "\n",
    "### Key Concepts\n",
    "\n",
    "**Model:** Which LLM to use (GPT-4, Claude, etc.)\n",
    "**Temperature:** Creativity (0 = precise, 1 = random)\n",
    "**Prompt:** What you ask the LLM\n",
    "**Response:** What the LLM sends back\n",
    "**response.content:** The actual text (response also has metadata)\n",
    "\n",
    "### Common Questions Here\n",
    "\n",
    "**Q: Why temperature 0.7?**\n",
    "A: It is arbitrary. 0 is precise, 1 is random. 0.7 is a middle ground. For agents, we use 0 (more predictable). For creative tasks, use 0.8-0.9.\n",
    "\n",
    "**Q: How much does this cost?**\n",
    "A: GPT-4-turbo costs about GBP 0.001 per response for simple questions. You get GBP 5 free credit with OpenAI.\n",
    "\n",
    "**Q: What is response.content?**\n",
    "A: Response is an object. It has .content (text), .usage (token count), and other metadata. We just want the text, so we use .content.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EXERCISE 1: Write Your Own Prompt\n",
    "\n",
    "### Student Instructions\n",
    "1. Replace the placeholder text with your own question\n",
    "2. Run the cell\n",
    "3. See what the LLM responds\n",
    "\n",
    "### Expected Student TODOs\n",
    "\n",
    "**What students see:**\n",
    "```python\n",
    "your_prompt = \"YOUR QUESTION HERE\"\n",
    "```\n",
    "\n",
    "### Correct Solution\n",
    "\n",
    "**Example solution 1:**\n",
    "```python\n",
    "your_prompt = \"Why is Python better than JavaScript?\"\n",
    "```\n",
    "\n",
    "**Example solution 2:**\n",
    "```python\n",
    "your_prompt = \"What is a cool fact about AI?\"\n",
    "```\n",
    "\n",
    "**Example solution 3:**\n",
    "```python\n",
    "your_prompt = \"Tell me a funny joke about programming\"\n",
    "```\n",
    "\n",
    "### What You Should See\n",
    "When you run this cell, you should see:\n",
    "- The student's prompt printed\n",
    "- A response from the LLM about that topic\n",
    "- No errors\n",
    "\n",
    "### Acceptance Criteria\n",
    "- The cell runs without errors\n",
    "- The LLM returns a response\n",
    "- The response is related to the prompt (usually is)\n",
    "\n",
    "### Common Issues and Solutions\n",
    "\n",
    "**Issue: NameError - \"llm not defined\"**\n",
    "- Solution: Student skipped the DEMO cell. Have them run it first.\n",
    "\n",
    "**Issue: \"Timeout\" or \"Connection error\"**\n",
    "- Solution: Internet issues or OpenAI is down. Try again in 30 seconds.\n",
    "\n",
    "**Issue: \"Rate limit exceeded\"**\n",
    "- Solution: Student (or whole class) made too many calls. Wait 1 minute.\n",
    "\n",
    "### Timing\n",
    "- Student completion: 1-2 minutes\n",
    "- First student done usually after 1 minute\n",
    "- Ask for volunteers to share their prompts and responses\n",
    "\n",
    "### Instructor Note\n",
    "You should test this yourself beforehand. Run it with a prompt like \"What is LangChain?\" to verify it works and see how long it takes.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Change this prompt to something interesting\n",
    "# Examples:\n",
    "# - \"Why is Python better than JavaScript?\"\n",
    "# - \"What's a cool fact about AI?\"\n",
    "# - \"Tell me a funny joke about programming\"\n",
    "# - \"What should I build as my first AI project?\"\n",
    "\n",
    "your_prompt = \"TODO: Write your own prompt here\"\n",
    "\n",
    "# Run it\n",
    "response = llm.invoke(your_prompt)\n",
    "print(f\"\\nYour prompt: {your_prompt}\")\n",
    "print(f\"\\nResponse: {response.content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART 3: Building Your First Agent\n",
    "## Duration: 7 minutes\n",
    "\n",
    "## Teaching Notes\n",
    "\n",
    "### What is an Agent?\n",
    "- \"An agent is an LLM that can use TOOLS to solve problems\"\n",
    "- It is not just retrieving data - it is DECIDING what to do\n",
    "- Example: Weather question → Agent uses weather tool → Gives answer\n",
    "\n",
    "### Key Insight\n",
    "- **Without tools:** LLM only knows what was in training data\n",
    "- **With tools:** LLM can access real-time data, compute, anything\n",
    "\n",
    "### What to Emphasise\n",
    "- Agent decides which tool to use\n",
    "- Agent reads the tool result\n",
    "- Agent formulates final answer\n",
    "- This is autonomous decision-making\n",
    "\n",
    "### Learning Outcome\n",
    "Students should understand:\n",
    "- What tools are\n",
    "- How agents decide to use tools\n",
    "- How to define custom tools\n",
    "- How to run an agent\n",
    "\n",
    "### Timing\n",
    "- Tool definition cell: 2 seconds\n",
    "- Agent creation cell: 5 seconds (first time, hub.pull takes time)\n",
    "- Agent execution cell: 5-10 seconds\n",
    "- Explanation: 3-4 minutes\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Define Tools (Functions)\n",
    "\n",
    "### Teaching Script\n",
    "\"First, we need to tell the agent what it can DO. These are called tools.\"\n",
    "\n",
    "\"A tool is just a Python function with documentation.\"\n",
    "\n",
    "\"We use the @tool decorator from LangChain to mark functions as tools. The docstring is crucial - it tells the agent what the tool does.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools import tool\n",
    "\n",
    "# Define Tool 1: Search Wikipedia\n",
    "@tool\n",
    "def search_wikipedia(query: str) -> str:\n",
    "    \"\"\"\n",
    "    Search Wikipedia for information about a topic.\n",
    "    Use this to find facts and background information.\n",
    "    \"\"\"\n",
    "    # In real life, this would call actual Wikipedia API\n",
    "    # For demo, we simulate it\n",
    "    return f\"Wikipedia results for '{query}': [Found detailed information about {query}]\"\n",
    "\n",
    "# Define Tool 2: Do Math\n",
    "@tool\n",
    "def calculate(expression: str) -> str:\n",
    "    \"\"\"\n",
    "    Calculate a mathematical expression.\n",
    "    Use this for maths problems, statistics, etc.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        result = eval(expression)\n",
    "        return f\"Result: {expression} = {result}\"\n",
    "    except:\n",
    "        return f\"Error: Could not calculate {expression}\"\n",
    "\n",
    "print(\"✓ Tools defined\")\n",
    "print(f\"  - search_wikipedia\")\n",
    "print(f\"  - calculate\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Create an Agent\n",
    "\n",
    "### Teaching Script\n",
    "\"Now we give these tools to the LLM and tell it to be an agent.\"\n",
    "\n",
    "\"The agent will decide which tool to use based on the question.\"\n",
    "\n",
    "\"We use hub.pull() to get a pre-made prompt template. This tells the LLM how to be an agent.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import create_tool_calling_agent, AgentExecutor\n",
    "from langchain import hub\n",
    "\n",
    "# Create the agent with our tools\n",
    "llm = ChatOpenAI(model=\"gpt-4-turbo\", temperature=0)\n",
    "\n",
    "# Get a pre-made prompt template for tool-using agents\n",
    "# Note: This requires internet (pulls from hub.langchain.com)\n",
    "prompt = hub.pull(\"hwchase17/openai-tools-agent\")\n",
    "\n",
    "# Define which tools the agent can use\n",
    "tools = [search_wikipedia, calculate]\n",
    "\n",
    "# Create the agent\n",
    "agent = create_tool_calling_agent(llm, tools, prompt)\n",
    "\n",
    "# Create an executor (runs the agent)\n",
    "executor = AgentExecutor(\n",
    "    agent=agent,\n",
    "    tools=tools,\n",
    "    verbose=True  # Show what the agent is thinking\n",
    ")\n",
    "\n",
    "print(\"✓ Agent created and ready to use\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Run the Agent\n",
    "\n",
    "### Teaching Script\n",
    "\"Watch what happens. The agent will see the question,\"\n",
    "\"decide which tool to use, use it, and give you an answer.\"\n",
    "\"Notice it shows its THINKING in verbose mode.\"\n",
    "\n",
    "### Important Note\n",
    "Point out to students the verbose output. Specifically:\n",
    "- The THOUGHT section (what the agent is thinking)\n",
    "- The ACTION section (which tool it chose and why)\n",
    "- The OBSERVATION section (what the tool returned)\n",
    "- The FINAL ANSWER section (the agent's synthesis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the agent with a question\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"AGENT DEMO: Calculate something and explain it\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "result = executor.invoke({\n",
    "    \"input\": \"What is 15 * 12? Then search for what that number means.\"\n",
    "})\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"FINAL ANSWER:\")\n",
    "print(\"=\"*70)\n",
    "print(result[\"output\"])\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What Just Happened?\n",
    "\n",
    "### Agent's Thought Process (From Verbose Output)\n",
    "\n",
    "```\n",
    "1. THOUGHT: \"User asked for 15*12 and then search for the result\"\n",
    "2. ACTION: Use 'calculate' tool with '15*12'\n",
    "3. OBSERVATION: \"Result: 15*12 = 180\"\n",
    "4. THOUGHT: \"Now I should search for 180\"\n",
    "5. ACTION: Use 'search_wikipedia' with '180'\n",
    "6. OBSERVATION: \"Wikipedia results for '180': [Found...]\"\n",
    "7. THOUGHT: \"I have all the info. Let me synthesise the answer\"\n",
    "8. FINAL ANSWER: \"15*12 = 180. In history/maths, 180 represents...\"\n",
    "```\n",
    "\n",
    "### Key Insight\n",
    "**The agent DECIDED what to do. It was not programmed to search. It chose to!**\n",
    "\n",
    "### Common Questions Here\n",
    "\n",
    "**Q: How does the agent know which tool to use?**\n",
    "A: The LLM reads the tool descriptions (the docstrings) and decides. It is the same pattern it learned in training - understanding context and making decisions.\n",
    "\n",
    "**Q: What if the agent picks the wrong tool?**\n",
    "A: Sometimes it does! If the tool returns bad data, the agent sees that and adjusts. It can even try a different tool.\n",
    "\n",
    "**Q: Can the agent use multiple tools in one response?**\n",
    "A: Yes! As you saw, it used calculate, then search_wikipedia. It can chain them.\n",
    "\n",
    "**Q: Why temperature=0 here but 0.7 earlier?**\n",
    "A: Agents need to be deterministic and logical. 0 temperature means precise decisions. For creative tasks, use higher temperature.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART 4: HANDS-ON LAB\n",
    "## Build a Colour-Arguing Agent\n",
    "## Duration: 15 minutes\n",
    "\n",
    "## Challenge Overview\n",
    "\n",
    "Students will:\n",
    "1. Pick a colour\n",
    "2. Define 2-3 tools that help argue for that colour\n",
    "3. Create an agent that uses those tools\n",
    "4. Have the agent make a passionate argument\n",
    "\n",
    "## Success Criteria\n",
    "\n",
    "- Agent runs without errors\n",
    "- Agent uses at least one tool\n",
    "- Agent produces an argument for its colour\n",
    "- Response is 3-5 sentences long\n",
    "\n",
    "## Ideas for Tools\n",
    "\n",
    "- Search for facts about the colour\n",
    "- Find where the colour appears in nature\n",
    "- Find cultural significance\n",
    "- Search for psychology facts about the colour\n",
    "- Find famous things that are that colour\n",
    "\n",
    "## Timing\n",
    "\n",
    "- Step 1 (define tools): 3 minutes\n",
    "- Step 2 (create agent): 2 minutes (mostly waiting for hub.pull)\n",
    "- Step 3 (create prompt): 3 minutes (thinking time)\n",
    "- Step 4 (run agent): 5-10 seconds\n",
    "- Debugging: variable\n",
    "\n",
    "## Instructor Pre-Testing\n",
    "\n",
    "Test the lab yourself first. Here is an example:\n",
    "\n",
    "**Colour:** Blue\n",
    "\n",
    "**Expected Tool Output:**\n",
    "- Tool 1: \"Found facts: Blue is associated with calmness\"\n",
    "- Tool 2: \"In nature, Blue is used for water and sky\"\n",
    "\n",
    "**Expected Agent Response (4-6 sentences):**\n",
    "- Something like: \"Blue is the best colour because it represents calm and stability. In nature, blue dominates our skies and oceans, making it the most abundant colour. Psychologically, people find blue soothing and trust-worthy, which is why it is used in corporate branding. Plus, blue is associated with the vastness of space and human freedom!\"\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Starter Template\n",
    "\n",
    "### Student Tasks\n",
    "\n",
    "Students will see cells with multiple TODO sections. Here is what they look like and what you should expect.\n",
    "\n",
    "---\n",
    "\n",
    "## CELL 1: Define Your Tools\n",
    "\n",
    "### What Student Sees\n",
    "\n",
    "```python\n",
    "# TODO: Pick your colour\n",
    "MY_COLOUR = \"TODO: Choose: Red, Green, Blue, Yellow, Purple, etc.\"\n",
    "\n",
    "# TODO: Define Tool 1\n",
    "@tool\n",
    "def search_colour_facts(topic: str) -> str:\n",
    "    \"\"\"\n",
    "    Search for interesting facts about a colour.\n",
    "    \"\"\"\n",
    "    return f\"Found facts: {MY_COLOUR} is associated with {topic}\"\n",
    "\n",
    "# TODO: Define Tool 2\n",
    "@tool\n",
    "def search_colour_usage(domain: str) -> str:\n",
    "    \"\"\"\n",
    "    Search for where your colour is used.\n",
    "    \"\"\"\n",
    "    return f\"In {domain}, {MY_COLOUR} is used for important things\"\n",
    "```\n",
    "\n",
    "### Expected Student Solution\n",
    "\n",
    "**Example 1 (Minimal change):**\n",
    "```python\n",
    "MY_COLOUR = \"Green\"\n",
    "# Everything else stays the same (the tools are already defined as templates)\n",
    "```\n",
    "\n",
    "**Example 2 (Better version):**\n",
    "```python\n",
    "MY_COLOUR = \"Purple\"\n",
    "\n",
    "@tool\n",
    "def search_colour_facts(topic: str) -> str:\n",
    "    \"\"\"\n",
    "    Search for interesting facts about a colour.\n",
    "    \"\"\"\n",
    "    return f\"{MY_COLOUR} is associated with {topic}\"\n",
    "\n",
    "@tool\n",
    "def search_colour_usage(domain: str) -> str:\n",
    "    \"\"\"\n",
    "    Search for where your colour is used.\n",
    "    \"\"\"\n",
    "    return f\"{MY_COLOUR} appears in {domain}\"\n",
    "```\n",
    "\n",
    "**Example 3 (Advanced - adds 3rd tool):**\n",
    "```python\n",
    "MY_COLOUR = \"Red\"\n",
    "\n",
    "# Same tool 1 and 2 as above, plus:\n",
    "\n",
    "@tool\n",
    "def search_psychology(aspect: str) -> str:\n",
    "    \"\"\"Find psychological facts about your colour\"\"\"\n",
    "    return f\"{MY_COLOUR} makes people feel {aspect}\"\n",
    "```\n",
    "\n",
    "### What You Should See\n",
    "When you run this cell:\n",
    "- No errors\n",
    "- Output: \"✓ Defined tools for [COLOUR]\"\n",
    "\n",
    "### Acceptance Criteria\n",
    "- MY_COLOUR is not still the TODO placeholder\n",
    "- Cell runs without errors\n",
    "- At least the two template tools are present\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools import tool\n",
    "from langchain.agents import create_tool_calling_agent, AgentExecutor\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain import hub\n",
    "\n",
    "# ============================================\n",
    "# STEP 1: Define Your Tools\n",
    "# ============================================\n",
    "\n",
    "# TODO: Pick your colour\n",
    "MY_COLOUR = \"TODO: Choose: Red, Green, Blue, Yellow, Purple, etc.\"\n",
    "\n",
    "# TODO: Define Tool 1\n",
    "# Make up a tool that finds facts about your colour\n",
    "@tool\n",
    "def search_colour_facts(topic: str) -> str:\n",
    "    \"\"\"\n",
    "    Search for interesting facts about a colour.\n",
    "    \"\"\"\n",
    "    return f\"Found facts: {MY_COLOUR} is associated with {topic}\"\n",
    "\n",
    "# TODO: Define Tool 2\n",
    "# Make up another tool\n",
    "@tool\n",
    "def search_colour_usage(domain: str) -> str:\n",
    "    \"\"\"\n",
    "    Search for where your colour is used.\n",
    "    \"\"\"\n",
    "    return f\"In {domain}, {MY_COLOUR} is used for important things\"\n",
    "\n",
    "print(f\"✓ Defined tools for {MY_COLOUR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## CELL 2: Create the Agent\n",
    "\n",
    "### What Student Sees\n",
    "\n",
    "```python\n",
    "# TODO: Create LLM\n",
    "llm = ChatOpenAI(model=\"gpt-4-turbo\", temperature=0.7)\n",
    "\n",
    "# TODO: Get the agent prompt\n",
    "prompt = hub.pull(\"hwchase17/openai-tools-agent\")\n",
    "\n",
    "# TODO: List your tools\n",
    "tools = [search_colour_facts, search_colour_usage]\n",
    "\n",
    "# TODO: Create the agent\n",
    "agent = create_tool_calling_agent(llm, tools, prompt)\n",
    "\n",
    "# TODO: Create executor\n",
    "executor = AgentExecutor(\n",
    "    agent=agent,\n",
    "    tools=tools,\n",
    "    verbose=True\n",
    ")\n",
    "```\n",
    "\n",
    "### Expected Student Solution\n",
    "\n",
    "**Most students will not change anything here.** The code is already provided.\n",
    "\n",
    "**Some might:**\n",
    "- Change temperature to 0.8 or 0.9 (for more creativity)\n",
    "- Add a 3rd tool to the tools list: `tools = [search_colour_facts, search_colour_usage, search_psychology]`\n",
    "\n",
    "### What You Should See\n",
    "When you run this cell:\n",
    "- Wait 3-5 seconds for hub.pull()\n",
    "- No errors\n",
    "- Output: \"✓ Agent ready\"\n",
    "\n",
    "### Acceptance Criteria\n",
    "- Cell runs without errors\n",
    "- Agent is created successfully\n",
    "- No NameError (they defined tools in cell 1)\n",
    "\n",
    "### Common Issues\n",
    "\n",
    "**Issue: \"hub.pull() connection error\"**\n",
    "- Solution: Internet connectivity issue. Try again or use a different prompt template.\n",
    "- Fallback: Use a manual prompt string instead of hub.pull()\n",
    "\n",
    "**Issue: NameError \"search_colour_facts is not defined\"**\n",
    "- Solution: Student did not run cell 1 first. Have them run it.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# STEP 2: Create the Agent\n",
    "# ============================================\n",
    "\n",
    "# TODO: Create LLM (temperature=0.7 for creativity)\n",
    "llm = ChatOpenAI(model=\"gpt-4-turbo\", temperature=0.7)\n",
    "\n",
    "# TODO: Get the agent prompt template\n",
    "prompt = hub.pull(\"hwchase17/openai-tools-agent\")\n",
    "\n",
    "# TODO: List your tools\n",
    "tools = [search_colour_facts, search_colour_usage]\n",
    "\n",
    "# TODO: Create the agent\n",
    "agent = create_tool_calling_agent(llm, tools, prompt)\n",
    "\n",
    "# TODO: Create executor\n",
    "executor = AgentExecutor(\n",
    "    agent=agent,\n",
    "    tools=tools,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "print(f\"✓ Agent ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## CELL 3: Create Your Prompt\n",
    "\n",
    "### What Student Sees\n",
    "\n",
    "```python\n",
    "# TODO: Write a prompt that makes the agent argue for your colour\n",
    "# The more specific, the better the arguments!\n",
    "# Examples:\n",
    "# - \"You are a passionate RED enthusiast. Argue why RED is the best color!\"\n",
    "# - \"You love GREEN. Why is GREEN superior to all other colors? Use facts!\"\n",
    "# - \"BLUE is clearly the best color. Prove it using your tools.\"\n",
    "\n",
    "my_prompt = f\"\"\"\n",
    "You are a passionate advocate for {MY_COLOUR}.\n",
    "Your job is to argue convincingly why {MY_COLOUR} is the BEST colour.\n",
    "Use your tools to find facts and evidence.\n",
    "Be creative, persuasive, and fun!\n",
    "Give 3-4 strong reasons why {MY_COLOUR} is superior.\n",
    "\"\"\"\n",
    "```\n",
    "\n",
    "### Expected Student Solutions\n",
    "\n",
    "**Solution 1 (Minimal):**\n",
    "```python\n",
    "# They just use the provided prompt template as-is\n",
    "# This is fine! It is a good prompt.\n",
    "```\n",
    "\n",
    "**Solution 2 (Slightly modified):**\n",
    "```python\n",
    "my_prompt = f\"\"\"\n",
    "Pretend you are a passionate {MY_COLOUR} enthusiast.\n",
    "Convince me that {MY_COLOUR} is the best colour in the world.\n",
    "Use your tools to support your argument.\n",
    "Be funny and persuasive.\n",
    "\"\"\"\n",
    "```\n",
    "\n",
    "**Solution 3 (More creative):**\n",
    "```python\n",
    "my_prompt = f\"\"\"\n",
    "You are a marketing executive hired by a {MY_COLOUR} paint company.\n",
    "Write a campaign explaining why {MY_COLOUR} is superior.\n",
    "Use facts and be persuasive.\n",
    "Make it 4-5 sentences.\n",
    "\"\"\"\n",
    "```\n",
    "\n",
    "### What You Should See\n",
    "When you run this cell:\n",
    "- No errors\n",
    "- Output showing \"✓ Prompt created\" and the prompt preview\n",
    "\n",
    "### Acceptance Criteria\n",
    "- my_prompt is not empty\n",
    "- It includes the colour name (via f-string)\n",
    "- It asks the agent to argue or persuade\n",
    "- It mentions using tools (optional but good)\n",
    "\n",
    "### Instructor Tips\n",
    "- Better prompts lead to better agent responses\n",
    "- Prompts that mention \"use your tools\" get agents to use tools more often\n",
    "- Longer prompts with more detail usually get better results\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# STEP 3: Create Your Prompt\n",
    "# ============================================\n",
    "\n",
    "# TODO: Write a prompt that makes the agent argue for your colour\n",
    "# The more specific, the better the arguments!\n",
    "\n",
    "my_prompt = f\"\"\"\n",
    "You are a passionate advocate for {MY_COLOUR}.\n",
    "Your job is to argue convincingly why {MY_COLOUR} is the BEST colour.\n",
    "Use your tools to find facts and evidence.\n",
    "Be creative, persuasive, and fun!\n",
    "Give 3-4 strong reasons why {MY_COLOUR} is superior.\n",
    "\"\"\"\n",
    "\n",
    "print(f\"✓ Prompt created\")\n",
    "print(f\"\\nPrompt preview:\\n{my_prompt}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## CELL 4: Run Your Agent!\n",
    "\n",
    "### What Student Sees\n",
    "\n",
    "```python\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(f\"{MY_COLOUR.upper()} AGENT - MAKING ARGUMENTS\")\n",
    "print(\"=\"*70 + \"\\n\")\n",
    "\n",
    "result = executor.invoke({\"input\": my_prompt})\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"FINAL ARGUMENT:\")\n",
    "print(\"=\"*70)\n",
    "print(result[\"output\"])\n",
    "print(\"=\"*70)\n",
    "```\n",
    "\n",
    "### What You Should See\n",
    "\n",
    "**Verbose output showing:**\n",
    "1. Agent thinking about what to do\n",
    "2. Agent choosing a tool\n",
    "3. Tool result\n",
    "4. More thinking\n",
    "5. Possibly another tool use\n",
    "6. Final answer (3-5 sentences arguing for the colour)\n",
    "\n",
    "**Example output:**\n",
    "```\n",
    "> Entering new AgentExecutor chain...\n",
    "THOUGHT: I need to argue why Blue is the best colour. Let me use my tools to find supporting facts.\n",
    "ACTION: search_colour_facts with topic 'psychology and emotion'\n",
    "OBSERVATION: Found facts: Blue is associated with calmness and trust\n",
    "THOUGHT: Good, now let me search for usage in nature and culture\n",
    "ACTION: search_colour_usage with domain 'nature'\n",
    "OBSERVATION: In nature, Blue is used for water and sky\n",
    "THOUGHT: I have enough facts. Now I can make my argument.\n",
    "\n",
    "FINAL ANSWER:\n",
    "Blue is the best colour for so many reasons. Psychologically, blue promotes calmness, trust, and stability - qualities we all need in life. In nature, blue is everywhere in our skies and oceans, making it the most abundant and essential colour. Blue has been used in art, design, and branding across cultures because it is universally beloved. Finally, blue is the colour of infinite possibilities - the colour of the vast universe and the deepest oceans!\n",
    "```\n",
    "\n",
    "### Acceptance Criteria\n",
    "- No errors\n",
    "- Agent used at least one tool\n",
    "- Agent produced an argument (3-5 sentences)\n",
    "- Argument is related to the colour\n",
    "- Output is printed clearly\n",
    "\n",
    "### Timing\n",
    "- First run: 5-15 seconds depending on API latency\n",
    "- Subsequent runs: 3-10 seconds\n",
    "\n",
    "### Common Issues\n",
    "\n",
    "**Issue: \"Agent didn't use any tools\"**\n",
    "- Problem: The agent decided it didn't need tools\n",
    "- Solution: Reword the prompt to explicitly say \"Use your tools to...\"\n",
    "- Alternative: Make tool names more relevant\n",
    "\n",
    "**Issue: \"Agent is repeating itself or stuck in a loop\"**\n",
    "- Problem: Sometimes happens with certain prompts\n",
    "- Solution: Reduce temperature (0.5 instead of 0.7)\n",
    "- Solution: Reword prompt to be more directive\n",
    "\n",
    "**Issue: \"Agent argument is too short\"**\n",
    "- Problem: Agent gave 1-2 sentences\n",
    "- Solution: Modify prompt to say \"Give a detailed argument with 4-5 sentences\"\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# STEP 4: Run Your Agent!\n",
    "# ============================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(f\"{MY_COLOUR.upper()} AGENT - MAKING ARGUMENTS\")\n",
    "print(\"=\"*70 + \"\\n\")\n",
    "\n",
    "result = executor.invoke({\"input\": my_prompt})\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"FINAL ARGUMENT:\")\n",
    "print(\"=\"*70)\n",
    "print(result[\"output\"])\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Lab Troubleshooting\n",
    "\n",
    "### Issue: \"NameError: name 'executor' is not defined\"\n",
    "- **Cause:** Cell 2 was not run before cell 4\n",
    "- **Solution:** Have student run all cells in order (1, 2, 3, 4)\n",
    "\n",
    "### Issue: \"API Rate Limit\"\n",
    "- **Cause:** Too many API calls from the whole class\n",
    "- **Solution:** Ask class to wait 1 minute before trying again\n",
    "- **Prevention:** Space out when different students run agents\n",
    "\n",
    "### Issue: \"hub.pull() timeout\"\n",
    "- **Cause:** Internet connectivity or hub.langchain.com is down\n",
    "- **Solution:** Provide a fallback prompt template in the cell\n",
    "\n",
    "### Issue: \"Agent response is short/not good\"\n",
    "- **Cause:** Weak prompt or tools not descriptive enough\n",
    "- **Solution:** Guide student to improve the prompt in cell 3\n",
    "- **Tips:**\n",
    "  - Make prompt more specific: \"Use your tools to find at least 3 facts\"\n",
    "  - Give character: \"You are an award-winning colour theorist arguing...\"\n",
    "  - Increase temperature: 0.8 or 0.9 for more creativity\n",
    "\n",
    "### Issue: \"Agent keeps using the same tool over and over\"\n",
    "- **Cause:** Tool names are vague or agent is confused\n",
    "- **Solution:** Reduce temperature to 0.3 to make decisions more deterministic\n",
    "- **Solution:** Rename tools to be more distinct\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extensions for Fast Finishers\n",
    "\n",
    "Have fast students try these:\n",
    "\n",
    "**Extension 1: Add a 3rd Tool**\n",
    "\n",
    "```python\n",
    "@tool\n",
    "def search_psychology(aspect: str) -> str:\n",
    "    \"\"\"Find psychological facts about your colour\"\"\"\n",
    "    return f\"{MY_COLOUR} makes people feel {aspect}\"\n",
    "```\n",
    "\n",
    "Then add it to tools list: `tools = [search_colour_facts, search_colour_usage, search_psychology]`\n",
    "\n",
    "**Extension 2: Make Your Agent Funny**\n",
    "\n",
    "Add to prompt: \"Be sarcastic and funny while arguing\"\n",
    "\n",
    "**Extension 3: Argue Against Another Colour**\n",
    "\n",
    "Add to prompt: \"Also explain why Red is worse than your colour\"\n",
    "\n",
    "**Extension 4: Change the Temperature**\n",
    "\n",
    "```python\n",
    "llm = ChatOpenAI(model=\"gpt-4-turbo\", temperature=0.9)  # More creative\n",
    "```\n",
    "\n",
    "**Extension 5: Add Personality**\n",
    "\n",
    "Change prompt to: \"You are a grumpy 80-year-old art professor arguing why...\" or \"You are a 10-year-old child excitedly explaining why...\"\n",
    "\n",
    "**Extension 6: Create a New Tool Type**\n",
    "\n",
    "```python\n",
    "@tool\n",
    "def count_uses(domain: str) -> str:\n",
    "    \"\"\"Count how many times the colour appears in a domain\"\"\"\n",
    "    return f\"{MY_COLOUR} appears in {domain} more than 100 times!\"\n",
    "```\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART 5: Recap and Handoff\n",
    "## Duration: 10 minutes\n",
    "\n",
    "## What You Learned\n",
    "\n",
    "**LangChain basics:**\n",
    "- What LangChain is and why it matters\n",
    "- How to import and use it\n",
    "\n",
    "**LLMs in Python:**\n",
    "- How to create an LLM instance\n",
    "- How to call it with a prompt\n",
    "- How to get and use the response\n",
    "\n",
    "**Tools:**\n",
    "- What tools are (functions the agent can call)\n",
    "- How to define tools with @tool decorator\n",
    "- How tools give agents real-world capabilities\n",
    "\n",
    "**Agents:**\n",
    "- What agents are (LLMs with decision-making)\n",
    "- How agents decide which tools to use\n",
    "- How to create and run agents\n",
    "- How agents reason and explain their thinking\n",
    "\n",
    "---\n",
    "\n",
    "## Real-World Applications\n",
    "\n",
    "What their code can do:\n",
    "- Chat with documents (agent reads PDFs and answers questions)\n",
    "- Autonomous research (agent finds info from multiple sources)\n",
    "- Code debugging (agent analyses code and suggests fixes)\n",
    "- Data analysis (agent processes data and creates reports)\n",
    "- Customer service (agent handles customer questions with tools)\n",
    "- Task automation (agent decides what actions to take)\n",
    "\n",
    "---\n",
    "\n",
    "## Key Takeaway\n",
    "\n",
    "**You just built what AI engineers do daily.**\n",
    "\n",
    "- Companies like OpenAI, Anthropic, and Google use this exact pattern\n",
    "- This is day 2-3 work at a real AI startup\n",
    "- They have portfolio-ready code\n",
    "- Employers specifically look for this skill\n",
    "\n",
    "---\n",
    "\n",
    "## Common Student Questions After This Lab\n",
    "\n",
    "**Q: Can I make the agent even smarter?**\n",
    "A: Yes! Next, we will learn LangGraph, which lets you chain multiple agents together and add memory.\n",
    "\n",
    "**Q: What if my tool fails?**\n",
    "A: Good question. We need error handling. Wrap your tool in try/except. The agent will see the error and adapt.\n",
    "\n",
    "**Q: Can I deploy this?**\n",
    "A: Absolutely. You can wrap it in a Flask/FastAPI web server and host it on AWS, Heroku, or similar.\n",
    "\n",
    "**Q: Can I use different LLMs?**\n",
    "A: Yes! Replace ChatOpenAI with Claude, Gemini, Llama, etc. The pattern is the same.\n",
    "\n",
    "**Q: How do I make this production-ready?**\n",
    "A: Add: error handling, logging, testing, rate limiting, caching, and monitoring.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary and Next Steps\n",
    "\n",
    "## What's Next?\n",
    "\n",
    "In the next section (LangGraph), students will:\n",
    "\n",
    "- Connect multiple agents working together\n",
    "- Add state management so agents share information\n",
    "- Visualise workflows as diagrams\n",
    "- Build production systems that companies actually deploy\n",
    "\n",
    "**Preview script:** \"What if you had 3 agents: one researches, one analyses, one makes decisions? They would need to pass information between them. That is what we are building next.\"\n",
    "\n",
    "---\n",
    "\n",
    "## Teaching Checklist\n",
    "\n",
    "Before each session:\n",
    "- [ ] Test all code cells yourself\n",
    "- [ ] Check API key is valid\n",
    "- [ ] Verify internet connectivity\n",
    "- [ ] Know how long each cell takes\n",
    "- [ ] Prepare example prompts for demonstrations\n",
    "- [ ] Have fallback solutions ready (e.g., gpt-3.5-turbo if gpt-4-turbo unavailable)\n",
    "\n",
    "During the session:\n",
    "- [ ] Type code slowly (do not copy-paste)\n",
    "- [ ] Explain each line\n",
    "- [ ] Show students the output\n",
    "- [ ] Celebrate when it works\n",
    "- [ ] Encourage students to tinker and experiment\n",
    "- [ ] Walk around checking on student progress\n",
    "- [ ] Help students debug issues\n",
    "\n",
    "After the session:\n",
    "- [ ] Ask for feedback\n",
    "- [ ] Collect student projects for assessment\n",
    "- [ ] Document any issues that came up\n",
    "- [ ] Prepare for next session\n",
    "\n",
    "---\n",
    "\n",
    "## Estimated Costs\n",
    "\n",
    "- Demo 1 (simple LLM call): ~GBP 0.001\n",
    "- Each student Exercise 1: ~GBP 0.001\n",
    "- Agent demo: ~GBP 0.002 (2 tool calls)\n",
    "- Each student lab (4 calls if agent uses 2 tools): ~GBP 0.003\n",
    "- **Total per student: ~GBP 0.01 (1 penny)**\n",
    "- **For 30 students: ~GBP 0.30**\n",
    "\n",
    "Students get GBP 5 free credits. No issue.\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}